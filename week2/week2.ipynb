{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.\n",
    "\n",
    "Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame. Then,\n",
    "\n",
    "A. Convert all text to lowercase letters.\n",
    "\n",
    "B. Remove all punctuation from the text.\n",
    "\n",
    "C. Remove stop words.\n",
    "\n",
    "D. Apply NLTK’s PorterStemmer.\n",
    "\n",
    "2. Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for model-building. Apply each of the following steps (individually) to the pre-processed data.\n",
    "\n",
    "A. Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "Follow-Up Question\n",
    "\n",
    "For the three techniques in problem (2) above, give an example where each would be useful.\n",
    "\n",
    "NOTE\n",
    "\n",
    "Running these steps on all of the data can take a while, so feel free to cut down on the number of texts (maybe 50,000) if your program takes too long to run. But be sure to select the text entries randomly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START READING\n",
      "END READING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>I genuinely can't understand how anyone can su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>As a reminder, this subreddit [is for civil di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>K. Don't explain why or anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>Ya, sociopaths are known for celebrating their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  Well it's great that he did something about th...\n",
       "1         0                       You are right Mr. President.\n",
       "2         0  You have given no input apart from saying I am...\n",
       "3         0  I get the frustration but the reason they want...\n",
       "4         0  I am far from an expert on TPP and I would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  I genuinely can't understand how anyone can su...\n",
       "949996    0  As a reminder, this subreddit [is for civil di...\n",
       "949997    0                  K. Don't explain why or anything.\n",
       "949998    0                                          [deleted]\n",
       "949999    0  Ya, sociopaths are known for celebrating their...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.\n",
    "# Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame. Then,\n",
    "import pandas as pd\n",
    "\n",
    "def readFile(f='controversial-comments.jsonl'):\n",
    "    print(\"START READING\")\n",
    "    df = pd.read_json(f, lines=True)\n",
    "    print(\"END READING\")\n",
    "    return df\n",
    "    \n",
    "df = readFile()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely can't understand how anyone can su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder, this subreddit [is for civil di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>k. don't explain why or anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>ya, sociopaths are known for celebrating their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well it's great that he did something about th...\n",
       "1         0                       you are right mr. president.\n",
       "2         0  you have given no input apart from saying i am...\n",
       "3         0  i get the frustration but the reason they want...\n",
       "4         0  i am far from an expert on tpp and i would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  i genuinely can't understand how anyone can su...\n",
       "949996    0  as a reminder, this subreddit [is for civil di...\n",
       "949997    0                  k. don't explain why or anything.\n",
       "949998    0                                          [deleted]\n",
       "949999    0  ya, sociopaths are known for celebrating their...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Convert all text to lowercase letters.\n",
    "df['txt'] = df['txt'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely cant understand how anyone can sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder this subreddit is for civil disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain why or anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopaths are known for celebrating their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well its great that he did something about tho...\n",
       "1         0                         you are right mr president\n",
       "2         0  you have given no input apart from saying i am...\n",
       "3         0  i get the frustration but the reason they want...\n",
       "4         0  i am far from an expert on tpp and i would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  i genuinely cant understand how anyone can sup...\n",
       "949996    0  as a reminder this subreddit is for civil disc...\n",
       "949997    0                     k dont explain why or anything\n",
       "949998    0                                            deleted\n",
       "949999    0  ya sociopaths are known for celebrating their ...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. Remove all punctuation from the text.\n",
    "\n",
    "import string\n",
    "# strip off punctuation characters as shown below\n",
    "# '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "df['txt'] = df['txt'].str.translate(str.maketrans('','',string.punctuation))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Remove stop words.\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwards')\n",
    "# installed through command line\n",
    "# Self Notes: python -m nltk.downloader stopwords\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "# This splits, removes any stopwords and then joins back the txt\n",
    "\n",
    "#df['txt_without_stopwords'] = df['txt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "df['txt'] = df['txt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well great something beliefs office doubt trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>given input apart saying wrong argument clearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>get frustration reason want way foundation com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>far expert tpp would tend agree lot problems u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>genuinely cant understand anyone support point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>reminder subreddit civil discussionhttpswwwred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopaths known celebrating positive feeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well great something beliefs office doubt trum...\n",
       "1         0                                 right mr president\n",
       "2         0    given input apart saying wrong argument clearly\n",
       "3         0  get frustration reason want way foundation com...\n",
       "4         0  far expert tpp would tend agree lot problems u...\n",
       "...     ...                                                ...\n",
       "949995    0  genuinely cant understand anyone support point...\n",
       "949996    0  reminder subreddit civil discussionhttpswwwred...\n",
       "949997    0                            k dont explain anything\n",
       "949998    0                                            deleted\n",
       "949999    0  ya sociopaths known celebrating positive feeli...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Apply NLTK’s PorterStemmer.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "df['txt'] = df['txt'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well great someth belief offic doubt trump wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>right mr presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>given input apart say wrong argument clearli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>get frustrat reason want way foundat complex p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>far expert tpp would tend agre lot problem und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>genuin cant understand anyon support point ok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>remind subreddit civil discussionhttpswwwreddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain anyth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>delet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopath known celebr posit feel fuck seri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well great someth belief offic doubt trump wou...\n",
       "1         0                                    right mr presid\n",
       "2         0       given input apart say wrong argument clearli\n",
       "3         0  get frustrat reason want way foundat complex p...\n",
       "4         0  far expert tpp would tend agre lot problem und...\n",
       "...     ...                                                ...\n",
       "949995    0  genuin cant understand anyon support point ok ...\n",
       "949996    0  remind subreddit civil discussionhttpswwwreddi...\n",
       "949997    0                               k dont explain anyth\n",
       "949998    0                                              delet\n",
       "949999    0  ya sociopath known celebr posit feel fuck seri...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of this in csv as backup for future steps\n",
    "df.to_csv(\"cleaned_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76868</th>\n",
       "      <td>0</td>\n",
       "      <td>assur gop hous would vote anyway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290295</th>\n",
       "      <td>0</td>\n",
       "      <td>aint brexit damn isnt exactli fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122412</th>\n",
       "      <td>0</td>\n",
       "      <td>like ive said there crazi work crazi cant penc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828059</th>\n",
       "      <td>0</td>\n",
       "      <td>remind subreddit civil discussionhttpswwwreddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705587</th>\n",
       "      <td>0</td>\n",
       "      <td>hack trump corner ever sinc privat meet trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>1</td>\n",
       "      <td>realli ruthless would gain money though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280107</th>\n",
       "      <td>0</td>\n",
       "      <td>get stump guis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343985</th>\n",
       "      <td>0</td>\n",
       "      <td>lol vote clinton shut fuck vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677357</th>\n",
       "      <td>0</td>\n",
       "      <td>he go declar presid regardless elect day resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125140</th>\n",
       "      <td>0</td>\n",
       "      <td>gt act behalf without knowledg consent plausib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "76868     0                   assur gop hous would vote anyway\n",
       "290295    0                 aint brexit damn isnt exactli fuck\n",
       "122412    0  like ive said there crazi work crazi cant penc...\n",
       "828059    0  remind subreddit civil discussionhttpswwwreddi...\n",
       "705587    0  hack trump corner ever sinc privat meet trump ...\n",
       "...     ...                                                ...\n",
       "6134      1            realli ruthless would gain money though\n",
       "280107    0                                     get stump guis\n",
       "343985    0                     lol vote clinton shut fuck vox\n",
       "677357    0  he go declar presid regardless elect day resul...\n",
       "125140    0  gt act behalf without knowledg consent plausib...\n",
       "\n",
       "[28500 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Now that the data is pre-processed, you will apply three different techniques \n",
    "# to get it into a usable form for model-building. Apply each of the following steps \n",
    "# (individually) to the pre-processed data.\n",
    "# A. Convert each text entry into a word-count vector \n",
    "# (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "# Not able to run the program with full data. So reducing the sample size\n",
    "dfsample = df.sample(frac = 0.03)\n",
    "dfsample\n",
    "\n",
    "# Self Notes - https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type\n",
    "# Getting - MemoryError: Unable to allocate array with shape (950000, 226148) and data type int64\n",
    "# Unable to run with 0.05, reducing the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>0000000</th>\n",
       "      <th>00000013</th>\n",
       "      <th>00001</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>00224</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>010</th>\n",
       "      <th>...</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zuckerburg</th>\n",
       "      <th>zumwalt</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zyxsubject</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzlist</th>\n",
       "      <th>ˈperəˌdīm</th>\n",
       "      <th>кофе</th>\n",
       "      <th>яepublican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28500 rows × 23116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  0000000  00000013  00001  001  002  00224  005  01  010  ...  zuck  \\\n",
       "0       0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "1       0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "2       0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "3       0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "4       0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "...    ..      ...       ...    ...  ...  ...    ...  ...  ..  ...  ...   ...   \n",
       "28495   0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "28496   0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "28497   0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "28498   0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "28499   0        0         0      0    0    0      0    0   0    0  ...     0   \n",
       "\n",
       "       zuckerburg  zumwalt  zwick  zyxsubject  zz  zzlist  ˈperəˌdīm  кофе  \\\n",
       "0               0        0      0           0   0       0          0     0   \n",
       "1               0        0      0           0   0       0          0     0   \n",
       "2               0        0      0           0   0       0          0     0   \n",
       "3               0        0      0           0   0       0          0     0   \n",
       "4               0        0      0           0   0       0          0     0   \n",
       "...           ...      ...    ...         ...  ..     ...        ...   ...   \n",
       "28495           0        0      0           0   0       0          0     0   \n",
       "28496           0        0      0           0   0       0          0     0   \n",
       "28497           0        0      0           0   0       0          0     0   \n",
       "28498           0        0      0           0   0       0          0     0   \n",
       "28499           0        0      0           0   0       0          0     0   \n",
       "\n",
       "       яepublican  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "28495           0  \n",
       "28496           0  \n",
       "28497           0  \n",
       "28498           0  \n",
       "28499           0  \n",
       "\n",
       "[28500 rows x 23116 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bag_of_words\n",
    "#dfsample\n",
    "bag_of_words = count.fit_transform(np.array(dfsample['txt']))\n",
    "arr = bag_of_words.toarray()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns= count.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Convert each text entry into a part-of-speech tag vector \n",
    "# (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "df = pd.read_csv(\"cleaned_file.csv\", index_col=0)\n",
    "dfsample = df.sample(frac = 0.03)\n",
    "\n",
    "#for first time only\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#dfsample['token']=pos_tag(word_tokenize(dfsample['txt']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605483</th>\n",
       "      <td>0</td>\n",
       "      <td>im normal dont interest polit typic wait ive w...</td>\n",
       "      <td>[(im, NN), (normal, JJ), (dont, JJ), (interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504854</th>\n",
       "      <td>0</td>\n",
       "      <td>longer hour work</td>\n",
       "      <td>[(longer, RB), (hour, NN), (work, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471043</th>\n",
       "      <td>0</td>\n",
       "      <td>jew vote trump think would show muslim black p...</td>\n",
       "      <td>[(jew, JJ), (vote, NN), (trump, NN), (think, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425409</th>\n",
       "      <td>0</td>\n",
       "      <td>berni trump like broken clock agre correct ide...</td>\n",
       "      <td>[(berni, JJ), (trump, NN), (like, IN), (broken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831703</th>\n",
       "      <td>0</td>\n",
       "      <td>understood he huge trump apologist ahol</td>\n",
       "      <td>[(understood, NN), (he, PRP), (huge, JJ), (tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517425</th>\n",
       "      <td>0</td>\n",
       "      <td>import differ though hillari go turn even coun...</td>\n",
       "      <td>[(import, NN), (differ, NN), (though, IN), (hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>remov</td>\n",
       "      <td>[(remov, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55077</th>\n",
       "      <td>0</td>\n",
       "      <td>im okay</td>\n",
       "      <td>[(im, NN), (okay, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427710</th>\n",
       "      <td>0</td>\n",
       "      <td>seced state requir said state approv congress ...</td>\n",
       "      <td>[(seced, VBN), (state, NN), (requir, NN), (sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859188</th>\n",
       "      <td>0</td>\n",
       "      <td>allow</td>\n",
       "      <td>[(allow, VB)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "605483    0  im normal dont interest polit typic wait ive w...   \n",
       "504854    0                                   longer hour work   \n",
       "471043    0  jew vote trump think would show muslim black p...   \n",
       "425409    0  berni trump like broken clock agre correct ide...   \n",
       "831703    0            understood he huge trump apologist ahol   \n",
       "...     ...                                                ...   \n",
       "517425    0  import differ though hillari go turn even coun...   \n",
       "2499      0                                              remov   \n",
       "55077     0                                            im okay   \n",
       "427710    0  seced state requir said state approv congress ...   \n",
       "859188    0                                              allow   \n",
       "\n",
       "                                                tokenized  \n",
       "605483  [(im, NN), (normal, JJ), (dont, JJ), (interest...  \n",
       "504854             [(longer, RB), (hour, NN), (work, NN)]  \n",
       "471043  [(jew, JJ), (vote, NN), (trump, NN), (think, N...  \n",
       "425409  [(berni, JJ), (trump, NN), (like, IN), (broken...  \n",
       "831703  [(understood, NN), (he, PRP), (huge, JJ), (tru...  \n",
       "...                                                   ...  \n",
       "517425  [(import, NN), (differ, NN), (though, IN), (hi...  \n",
       "2499                                        [(remov, NN)]  \n",
       "55077                              [(im, NN), (okay, NN)]  \n",
       "427710  [(seced, VBN), (state, NN), (requir, NN), (sai...  \n",
       "859188                                      [(allow, VB)]  \n",
       "\n",
       "[28500 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tagged\n",
    "#dfsample['tokenized'] = dfsample['txt'].apply(lambda x: [].append([pos_tag(word_tokenize(word)) for word in x.split()]))\n",
    "def tokenizer(arr):\n",
    "    tokens = []\n",
    "    for word in arr:\n",
    "        tokens.append(pos_tag(word_tokenize(str(word))))\n",
    "    return tokens\n",
    "\n",
    "dfsample['tokenized'] = tokenizer(dfsample['txt'])\n",
    "dfsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector \n",
    "# (see section 6.9 in the Machine Learning with Python Cookbook).\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = tfidf.fit_transform(dfsample['txt'].values.astype('U'))\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im 11398\n",
      "normal 14974\n",
      "dont 6283\n",
      "interest 11842\n",
      "polit 16423\n",
      "typic 21966\n",
      "wait 23074\n",
      "ive 12086\n",
      "watch 23175\n",
      "three 21341\n",
      "debat 5524\n",
      "make 13391\n",
      "inform 11689\n",
      "decis 5561\n",
      "would 23712\n",
      "vote 23002\n",
      "elect 6716\n",
      "someth 19715\n",
      "els 6769\n",
      "yesterday 23877\n",
      "point 16383\n",
      "done 6267\n",
      "due 6459\n",
      "dilig 5941\n",
      "confid 4774\n",
      "clinton 4409\n",
      "far 7399\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(tfidf.vocabulary_.items()):\n",
    "    print(k, v)\n",
    "    if i > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-Up Question\n",
    "#### For the three techniques in problem (2) above, give an example where each would be useful.\n",
    "A. Bag of Words models is considered to check if a known word occurs in a document or not. It gives each string as a 1X(number of words in vocabulary) array which tells how many times a particular world is contained in each sentence. It does not care about meaning, context, and order in which they appear. This gives the insight that similar documents will have word counts similar to each other. In other words, the more similar the words in two documents, the more similar the documents can be.\n",
    "\n",
    "Usage wise, we may use this in detecting spam mails.\n",
    "\n",
    "B. POS tagging can be really useful, particularly if you have words or tokens that can have multiple POS tags. For instance, the word \"google\" can be used as both a noun and verb, depending upon the context. While processing natural language, it is important to identify this difference.\n",
    "\n",
    "Usage wise, we may try to identify the gender or demographics of the people or person conversing, for eg. if we anlayze chat texts, we may be able to identify the person gender or which part of the world he is from etc.\n",
    "\n",
    "C. Using the term frequency-inverse document frequency (tfidf) vector approach, we are able to find which words appear the most in a document. More number of times a word appears, it is an evidence that the document is about that topic. So we may be able to identify the context of the document.\n",
    "\n",
    "Usage wise, we may be able to identify the context of a discussion or document. So lets say, If we are looking for some specific context we may use a combination of Bag of Words approach and tfidf to understand which conversations in a chat are required to be further analyzed and which may be discarded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
